{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "japanese-rendering",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, GRU\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, os \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "filename = \"subtitle.txt\"\n",
    "raw_text = open(filename, 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "regulation-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
    "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "    return txt \n",
    "raw_text = clean_text(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dependent-tragedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "def get_sequence_of_tokens(corpus):\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    \n",
    "    ## convert data to sequence of tokens \n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    return input_sequences, total_words\n",
    "inp_sequences, total_words = get_sequence_of_tokens(raw_text.split('\\n\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sustainable-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padded_sequences(input_sequences):\n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "    \n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = ku.to_categorical(label, num_classes=total_words)\n",
    "    return predictors, label, max_sequence_len\n",
    "\n",
    "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "global-configuration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 91, 10)            1740      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 128)               53376     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 174)               44718     \n",
      "=================================================================\n",
      "Total params: 132,858\n",
      "Trainable params: 132,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(max_sequence_len, total_words):\n",
    "    input_len = max_sequence_len - 1\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add Input Embedding Layer\n",
    "    model.add(Embedding(total_words, 10, input_length=input_len))\n",
    "    \n",
    "    # Add Hidden Layer 1 - LSTM Layer\n",
    "    model.add(GRU(128))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    # Add Output Layer\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(max_sequence_len, total_words)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cardiovascular-campaign",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 5.1601 - accuracy: 0.0114\n",
      "Epoch 2/50\n",
      "264/264 [==============================] - 1s 2ms/step - loss: 5.1514 - accuracy: 0.0379\n",
      "Epoch 3/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 5.1397 - accuracy: 0.0417\n",
      "Epoch 4/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 5.0918 - accuracy: 0.0417\n",
      "Epoch 5/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 5.0239 - accuracy: 0.0417\n",
      "Epoch 6/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 5.0146 - accuracy: 0.0417\n",
      "Epoch 7/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 4.9725 - accuracy: 0.0417\n",
      "Epoch 8/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 4.9240 - accuracy: 0.0417\n",
      "Epoch 9/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 4.8959 - accuracy: 0.0417\n",
      "Epoch 10/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 4.8829 - accuracy: 0.0417\n",
      "Epoch 11/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 4.8654 - accuracy: 0.0417\n",
      "Epoch 12/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 4.8417 - accuracy: 0.0417\n",
      "Epoch 13/50\n",
      "264/264 [==============================] - 1s 2ms/step - loss: 4.8164 - accuracy: 0.0417\n",
      "Epoch 14/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 4.7828 - accuracy: 0.0417\n",
      "Epoch 15/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 4.7443 - accuracy: 0.0455\n",
      "Epoch 16/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 4.6960 - accuracy: 0.0417\n",
      "Epoch 17/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 4.6356 - accuracy: 0.0455\n",
      "Epoch 18/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 4.5720 - accuracy: 0.0530\n",
      "Epoch 19/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 4.4900 - accuracy: 0.0758\n",
      "Epoch 20/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 4.3774 - accuracy: 0.0833\n",
      "Epoch 21/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 4.2339 - accuracy: 0.0871\n",
      "Epoch 22/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 4.0596 - accuracy: 0.0985\n",
      "Epoch 23/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 3.8894 - accuracy: 0.1098\n",
      "Epoch 24/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 3.6758 - accuracy: 0.1402\n",
      "Epoch 25/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 3.4897 - accuracy: 0.1515\n",
      "Epoch 26/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 3.2826 - accuracy: 0.2008\n",
      "Epoch 27/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 3.1025 - accuracy: 0.1894\n",
      "Epoch 28/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 2.9113 - accuracy: 0.2614\n",
      "Epoch 29/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 2.7658 - accuracy: 0.2311\n",
      "Epoch 30/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 2.6271 - accuracy: 0.3106\n",
      "Epoch 31/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 2.4267 - accuracy: 0.3030\n",
      "Epoch 32/50\n",
      "264/264 [==============================] - 1s 2ms/step - loss: 2.2354 - accuracy: 0.4583\n",
      "Epoch 33/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 2.0022 - accuracy: 0.4735\n",
      "Epoch 34/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 1.8149 - accuracy: 0.5189\n",
      "Epoch 35/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 1.6734 - accuracy: 0.5644\n",
      "Epoch 36/50\n",
      "264/264 [==============================] - 1s 2ms/step - loss: 1.5930 - accuracy: 0.5985\n",
      "Epoch 37/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 1.4305 - accuracy: 0.6439\n",
      "Epoch 38/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 1.3126 - accuracy: 0.6780\n",
      "Epoch 39/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 1.1578 - accuracy: 0.7462\n",
      "Epoch 40/50\n",
      "264/264 [==============================] - 1s 2ms/step - loss: 1.0610 - accuracy: 0.7614\n",
      "Epoch 41/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.9906 - accuracy: 0.7727\n",
      "Epoch 42/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.8736 - accuracy: 0.8258\n",
      "Epoch 43/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.7905 - accuracy: 0.8333\n",
      "Epoch 44/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.7401 - accuracy: 0.8636\n",
      "Epoch 45/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.6554 - accuracy: 0.8636\n",
      "Epoch 46/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.6322 - accuracy: 0.8712\n",
      "Epoch 47/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.9167\n",
      "Epoch 48/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.9129\n",
      "Epoch 49/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.9280\n",
      "Epoch 50/50\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.9394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x28355a27148>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(predictors, label, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "advance-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = model.predict_classes(token_list, verbose=0)\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word,index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \"+output_word\n",
    "    return seed_text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "nominated-cuisine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Is Scattered By The Way Pathetic\n",
      "Potter Im Ron By The Way\n",
      "Can You Cant Ron Pleasure You\n"
     ]
    }
   ],
   "source": [
    "print (generate_text(\"This is\", 5, model, max_sequence_len))\n",
    "print (generate_text(\"Potter\", 5, model, max_sequence_len))\n",
    "print (generate_text(\"can\", 5, model, max_sequence_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "alternative-saskatchewan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gTTS in c:\\users\\suryaa\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: click in c:\\users\\suryaa\\anaconda3\\lib\\site-packages (from gTTS) (7.1.2)\n",
      "Requirement already satisfied: requests in c:\\users\\suryaa\\anaconda3\\lib\\site-packages (from gTTS) (2.25.1)\n",
      "Requirement already satisfied: six in c:\\users\\suryaa\\anaconda3\\lib\\site-packages (from gTTS) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\suryaa\\anaconda3\\lib\\site-packages (from requests->gTTS) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\suryaa\\anaconda3\\lib\\site-packages (from requests->gTTS) (1.26.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\suryaa\\anaconda3\\lib\\site-packages (from requests->gTTS) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\suryaa\\anaconda3\\lib\\site-packages (from requests->gTTS) (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gTTS\n",
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "mytext = generate_text(\"Potter\", 3, model, max_sequence_len)\n",
    "language = 'en'\n",
    "  \n",
    "myobj = gTTS(text=mytext, lang=language, slow=False)\n",
    "  \n",
    "myobj.save(\"predicted_audio.mp3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
